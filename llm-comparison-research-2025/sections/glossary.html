<!-- Glossary Section -->
<h2 class="section-header text-2xl font-bold mb-4 text-slate-800 dark:text-slate-200 cursor-pointer hover:text-blue-600 dark:hover:text-blue-400 select-none">ðŸ“š Glossary</h2>
<div class="section-content">
    <div class="grid grid-cols-1 md:grid-cols-2 gap-4">
        <!-- LLM -->
        <div class="bg-slate-50 dark:bg-slate-800 p-3 rounded-lg border border-slate-200 dark:border-slate-700">
            <h4 class="font-semibold text-slate-800 dark:text-slate-200">Large Language Models (LLMs)</h4>
            <p class="text-sm text-slate-600 dark:text-slate-400">AI systems trained on vast amounts of text data to understand and generate human-like text. Modern LLMs can process code, images, and other data types.</p>
        </div>

        <!-- Context Window -->
        <div class="bg-slate-50 dark:bg-slate-800 p-3 rounded-lg border border-slate-200 dark:border-slate-700">
            <h4 class="font-semibold text-slate-800 dark:text-slate-200">Context Window</h4>
            <p class="text-sm text-slate-600 dark:text-slate-400">The maximum amount of text an LLM can process in a single request, measured in tokens. Larger windows enable processing of entire documents or codebases.</p>
        </div>

        <!-- SWE-bench -->
        <div class="bg-slate-50 dark:bg-slate-800 p-3 rounded-lg border border-slate-200 dark:border-slate-700">
            <h4 class="font-semibold text-slate-800 dark:text-slate-200">SWE-bench</h4>
            <p class="text-sm text-slate-600 dark:text-slate-400">Software Engineering benchmark measuring LLM ability to solve real-world coding problems from GitHub issues. Higher scores indicate better coding capabilities.</p>
        </div>

        <!-- Terminal-bench -->
        <div class="bg-slate-50 dark:bg-slate-800 p-3 rounded-lg border border-slate-200 dark:border-slate-700">
            <h4 class="font-semibold text-slate-800 dark:text-slate-200">Terminal-bench</h4>
            <p class="text-sm text-slate-600 dark:text-slate-400">Benchmark evaluating LLM ability to generate correct command-line instructions and complete terminal-based tasks. Essential for DevOps and system administration workflows.</p>
        </div>

        <!-- AIME 2025 -->
        <div class="bg-slate-50 dark:bg-slate-800 p-3 rounded-lg border border-slate-200 dark:border-slate-700">
            <h4 class="font-semibold text-slate-800 dark:text-slate-200">AIME 2025</h4>
            <p class="text-sm text-slate-600 dark:text-slate-400">American Invitational Mathematics Examination, a challenging competition-level math test used to evaluate LLM mathematical reasoning and problem-solving capabilities.</p>
        </div>

        <!-- Token -->
        <div class="bg-slate-50 dark:bg-slate-800 p-3 rounded-lg border border-slate-200 dark:border-slate-700">
            <h4 class="font-semibold text-slate-800 dark:text-slate-200">Token</h4>
            <p class="text-sm text-slate-600 dark:text-slate-400">The basic unit of text processing in LLMs. Roughly equivalent to 0.75 words in English. API pricing is typically based on token consumption.</p>
        </div>

        <!-- Knowledge Cutoff -->
        <div class="bg-slate-50 dark:bg-slate-800 p-3 rounded-lg border border-slate-200 dark:border-slate-700">
            <h4 class="font-semibold text-slate-800 dark:text-slate-200">Knowledge Cutoff</h4>
            <p class="text-sm text-slate-600 dark:text-slate-400">The date after which an LLM has no training data. More recent cutoffs mean the model knows about more current events and developments.</p>
        </div>

        <!-- Deep Think -->
        <div class="bg-slate-50 dark:bg-slate-800 p-3 rounded-lg border border-slate-200 dark:border-slate-700">
            <h4 class="font-semibold text-slate-800 dark:text-slate-200">Deep Think</h4>
            <p class="text-sm text-slate-600 dark:text-slate-400">Gemini's extended reasoning mode that takes additional time to work through complex problems step-by-step, providing more thorough and accurate responses.</p>
        </div>

        <!-- Tool-calling -->
        <div class="bg-slate-50 dark:bg-slate-800 p-3 rounded-lg border border-slate-200 dark:border-slate-700">
            <h4 class="font-semibold text-slate-800 dark:text-slate-200">Tool-calling</h4>
            <p class="text-sm text-slate-600 dark:text-slate-400">The ability of an LLM to interact with external services and APIs, enabling actions like web searches, code execution, or database queries within conversations.</p>
        </div>

        <!-- STEM Tasks -->
        <div class="bg-slate-50 dark:bg-slate-800 p-3 rounded-lg border border-slate-200 dark:border-slate-700">
            <h4 class="font-semibold text-slate-800 dark:text-slate-200">STEM Tasks</h4>
            <p class="text-sm text-slate-600 dark:text-slate-400">Science, Technology, Engineering, and Mathematics problems that require analytical thinking, numerical computation, and domain-specific knowledge.</p>
        </div>

        <!-- EQ -->
        <div class="bg-slate-50 dark:bg-slate-800 p-3 rounded-lg border border-slate-200 dark:border-slate-700">
            <h4 class="font-semibold text-slate-800 dark:text-slate-200">EQ (Emotional Intelligence)</h4>
            <p class="text-sm text-slate-600 dark:text-slate-400">A model's ability to understand and respond to human emotions appropriately, creating more natural and empathetic interactions.</p>
        </div>

        <!-- Multimodal -->
        <div class="bg-slate-50 dark:bg-slate-800 p-3 rounded-lg border border-slate-200 dark:border-slate-700">
            <h4 class="font-semibold text-slate-800 dark:text-slate-200">Multimodal</h4>
            <p class="text-sm text-slate-600 dark:text-slate-400">The ability to process and generate multiple types of content (text, images, audio, video) within a single model, without conversion between formats.</p>
        </div>

        <!-- Hybrid Reasoning -->
        <div class="bg-slate-50 dark:bg-slate-800 p-3 rounded-lg border border-slate-200 dark:border-slate-700">
            <h4 class="font-semibold text-slate-800 dark:text-slate-200">Hybrid Reasoning</h4>
            <p class="text-sm text-slate-600 dark:text-slate-400">A model capability featuring both instant responses and extended thinking modes, allowing users to choose between speed and depth of analysis.</p>
        </div>

        <!-- GPQA Diamond -->
        <div class="bg-slate-50 dark:bg-slate-800 p-3 rounded-lg border border-slate-200 dark:border-slate-700">
            <h4 class="font-semibold text-slate-800 dark:text-slate-200">GPQA Diamond</h4>
            <p class="text-sm text-slate-600 dark:text-slate-400">Graduate-level science question answering benchmark testing advanced reasoning. Scores reflect deep understanding of complex scientific topics.</p>
        </div>

        <!-- API Pricing -->
        <div class="bg-slate-50 dark:bg-slate-800 p-3 rounded-lg border border-slate-200 dark:border-slate-700">
            <h4 class="font-semibold text-slate-800 dark:text-slate-200">API Pricing</h4>
            <p class="text-sm text-slate-600 dark:text-slate-400">Cost structure for using LLMs via API, typically charged per million tokens with separate rates for input (prompts) and output (responses).</p>
        </div>

        <!-- Open-Source Model -->
        <div class="bg-slate-50 dark:bg-slate-800 p-3 rounded-lg border border-slate-200 dark:border-slate-700">
            <h4 class="font-semibold text-slate-800 dark:text-slate-200">Open-Source Model</h4>
            <p class="text-sm text-slate-600 dark:text-slate-400">LLMs with publicly available weights and code, allowing self-hosting and customization. Examples include DeepSeek-R1 and various community models.</p>
        </div>

        <!-- Thinking Mode -->
        <div class="bg-slate-50 dark:bg-slate-800 p-3 rounded-lg border border-slate-200 dark:border-slate-700">
            <h4 class="font-semibold text-slate-800 dark:text-slate-200">Thinking Mode</h4>
            <p class="text-sm text-slate-600 dark:text-slate-400">Extended reasoning capability where models deliberately work through problems step-by-step, trading response time for improved accuracy and depth.</p>
        </div>

        <!-- Prompt Engineering -->
        <div class="bg-slate-50 dark:bg-slate-800 p-3 rounded-lg border border-slate-200 dark:border-slate-700">
            <h4 class="font-semibold text-slate-800 dark:text-slate-200">Prompt Engineering</h4>
            <p class="text-sm text-slate-600 dark:text-slate-400">The practice of crafting effective inputs to LLMs to achieve desired outputs, including techniques for reducing token usage and improving response quality.</p>
        </div>

        <!-- Model Routing -->
        <div class="bg-slate-50 dark:bg-slate-800 p-3 rounded-lg border border-slate-200 dark:border-slate-700">
            <h4 class="font-semibold text-slate-800 dark:text-slate-200">Model Routing</h4>
            <p class="text-sm text-slate-600 dark:text-slate-400">The practice of directing different types of requests to appropriate LLMs based on task requirements, optimizing for both performance and cost.</p>
        </div>
    </div>
</div> 