<!DOCTYPE html>
<html lang="en" data-theme="light">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Document Digest Template</title>
    
    <!-- Tailwind CSS Play CDN -->
    <script src="https://cdn.tailwindcss.com"></script>
    <link rel="stylesheet" href="../styles.css">
    <script>
        tailwind.config = {
            darkMode: 'class',
        }
    </script>
</head>
<body class="bg-white dark:bg-slate-900 text-slate-800 dark:text-slate-200 transition-colors">
    
    <!-- Progress Bar -->
    <div class="progress-bar fixed top-0 left-0 h-1 bg-blue-500 z-50 transition-all duration-100"></div>
    
    <!-- Reading Time Display -->
    <div id="readingTimeDisplay" class="fixed top-2 left-4 px-3 py-1 bg-slate-100 dark:bg-slate-800 border border-slate-300 dark:border-slate-600 rounded-full text-xs text-slate-600 dark:text-slate-400 z-50 transition-colors">
        <span id="readingTimeText">ðŸ“– Calculating...</span>
    </div>
    
    <!-- Dark Mode Toggle -->
    <button id="themeToggle" class="fixed top-4 right-4 w-12 h-12 rounded-full bg-slate-100 dark:bg-slate-800 border border-slate-300 dark:border-slate-600 hover:bg-slate-200 dark:hover:bg-slate-700 flex items-center justify-center text-xl z-50 transition-colors">
        <span id="themeIcon">ðŸŒ™</span>
    </button>
    
    <!-- Table of Contents -->
    <div class="toc-container fixed top-0 right-0 h-screen w-72 bg-slate-50 dark:bg-slate-800 border-l border-slate-200 dark:border-slate-700 z-40 overflow-y-auto">
        <div class="absolute -left-10 top-1/2 -translate-y-1/2 w-10 h-15 bg-slate-50 dark:bg-slate-800 border border-r-0 border-slate-200 dark:border-slate-700 rounded-l-lg flex items-center justify-center cursor-pointer text-slate-600 dark:text-slate-400">
            â˜°
        </div>
        <div class="p-4">
            <h3 class="text-lg font-bold mb-4 text-slate-800 dark:text-slate-200">Contents</h3>
            <nav id="tocNav" class="space-y-2">
                <!-- TOC will be generated by JavaScript -->
            </nav>
        </div>
    </div>
    
    <!-- Main Content -->
    <main class="max-w-none mx-auto px-6 py-8" style="max-width: 70ch;">
        
        <!-- Prefix Panel -->
        <section class="bg-blue-50 dark:bg-blue-950 border-l-4 border-blue-400 dark:border-blue-500 p-4 rounded-r-lg mb-8">
            <h2 class="section-header text-xl font-semibold mb-3 text-slate-800 dark:text-slate-200 cursor-pointer hover:text-blue-600 dark:hover:text-blue-400 select-none">ðŸ“‹ How This Document Was Created</h2>
            <div class="section-content">
                <p class="text-sm text-slate-600 dark:text-slate-400 mb-2">
                    This document represents a condensed version of a longer work, transformed into an interactive web format. Here's what was retained, condensed, or omitted:
                </p>
                <ul class="text-sm text-slate-600 dark:text-slate-400 space-y-1 ml-4">
                    <li><strong>Retained:</strong> Core arguments, key insights, and main conclusions</li>
                    <li><strong>Condensed:</strong> Complex details simplified for broader accessibility</li>
                    <li><strong>Omitted:</strong> Repetitive sections, extensive citations, and tangential content</li>
                </ul>
            </div>
        </section>
        
        <!-- Document Summary -->
        <section class="mb-8">
            <h2 class="section-header text-2xl font-bold mb-4 text-slate-800 dark:text-slate-200 cursor-pointer hover:text-blue-600 dark:hover:text-blue-400 select-none">ðŸ“„ Abstract</h2>
            <div class="section-content">
                <p class="text-lg leading-relaxed text-slate-700 dark:text-slate-300 mb-4">
                    Large language models have demonstrated exceptional performance across multiple crosslingual NLP tasks, including machine translation (MT). However, persistent challenges remain in addressing context-sensitive units (CSUs), such as polysemous words. These CSUs not only affect the local translation accuracy of LLMs, but also affect LLMs' understanding capability for sentences and tasks, and even lead to translation failure. To address this problem, we propose a simple but effective method to enhance LLMs' MT capabilities by acquiring CSUs and applying semantic focus. Specifically, we dynamically analyze and identify translation challenges, then incorporate them into LLMs in a structured manner to mitigate mistranslations or misunderstandings of CSUs caused by information flattening. Efficiently activate LLMs to identify and apply relevant knowledge from its vast data pool in this way, ensuring more accurate translations for translating difficult terms. On a benchmark dataset of MT, our proposed method achieved competitive performance compared to multiple existing open-sourced MT baseline models. It demonstrates effectiveness and robustness across multiple language pairs, including both similar language pairs and distant language pairs. Notably, the proposed method requires no additional model training and enhances LLMs' performance across multiple NLP tasks with minimal resource consumption.
                </p>
            </div>
        </section>
        
        <!-- Content Sections -->
        <section class="mb-8">
            <h2 class="section-header text-2xl font-bold mb-4 text-slate-800 dark:text-slate-200 cursor-pointer hover:text-blue-600 dark:hover:text-blue-400 select-none">1. Introduction</h2>
            <div class="section-content">
                <p class="text-base leading-relaxed text-slate-700 dark:text-slate-300 mb-4">
                    The rapid development of large language models (LLMs) has revolutionized cross-lingual NLP tasks (Touvron et al., 2023 ; Zhang et al., 2024 ; Wang et al., 2024 ; OpenAI et al., 2024 ; Bubeck et al., 2023 ; He et al., 2024b), particularly in machine translation (MT). Current LLM-based translation paradigms primarily employ two approaches: prompt engineering and instruction fine-tuning. While these methods showcase impressive capabilities, several persistent challenges remain critical: systematic inaccuracies in translating certain context-sensitive units (CSUs), such as polysemous words. Additionally, these CSUs can impair the model's understanding of the entire sentence and may even lead to catastrophic failures, such as producing semantically incoherent outputs or complete translation abandonment. We think that one of the key reasons for the aforementioned issues lies in the bottleneck of LLMs' knowledge utilization for CSUs, leading to semantic ambiguity. Most LLMs-based MT methods treat the entire sentence as a homogeneous unit, but neglect the varying context-sensitive constituent words leading to varying translation difficulty. Specifically, a sentence to be translated is composed of several words, each with varying degrees of difficulty in translation. For example, the translation of a polysemous word is determined by contextual information, making it one of the challenging words. Furthermore, the accurate understanding of these challenging words plays a crucial role in whether LLMs can properly interpret the user's intent and provide a suitable translation.
                </p>
            </div>
        </section>
        
        <!-- Add more sections by copying the template above -->
        
        <!-- Glossary -->
        <section class="mb-8">
            <h2 class="section-header text-2xl font-bold mb-4 text-slate-800 dark:text-slate-200 cursor-pointer hover:text-blue-600 dark:hover:text-blue-400 select-none">ðŸ“š Glossary</h2>
            <div class="section-content">
                <div class="grid grid-cols-1 md:grid-cols-2 gap-4">
                    <!-- Copy this template for each glossary term -->
                    <div class="bg-slate-50 dark:bg-slate-800 p-3 rounded-lg border border-slate-200 dark:border-slate-700">
                        <h4 class="font-semibold text-slate-800 dark:text-slate-200">[Term]</h4>
                        <p class="text-sm text-slate-600 dark:text-slate-400">[Definition - keep it concise and clear]</p>
                    </div>
                    <!-- Add more terms as needed -->
                </div>
            </div>
        </section>
        
        <section class="mb-8">
            <h2 class="section-header text-2xl font-bold mb-4 text-slate-800 dark:text-slate-200 cursor-pointer hover:text-blue-600 dark:hover:text-blue-400 select-none">2. Preliminary Experiment</h2>
            <div class="section-content">
                <p class="text-base leading-relaxed text-slate-700 dark:text-slate-300 mb-4">
                    In this section, we conduct a series of experiments to explicit the impact of CSUs in the LLMs' MT task. We randomly select two English sentences containing polysemous words (words with multiple corresponding translations in Chinese) for translation experiments. Using a classic prompt template ("Translate the following sentence to Chinese:"), we let the LLMs provide translation results. The experimental results are shown in Table 1. The baseline model Llama3-8b produced incorrect translations for these polysemous words (highlighted in red). Subsequently, we tested the same prompt template with the inclusion of CSUs in this format, "Note: the following should be translated carefully + CSUs." The translation performance showed significant improvement. From Case 1 (the upper half of Table 1), it is evident that by highlighting the challenging words, i.e., CSUs, the model is able to provide more accurate translations (highlighted in blue) for the difficult parts. In Case 2 (the bottom half), we reasonably infer that CSUs influence the model's understanding of the sentence and the execution of the translation task, which leads to translation failure, i.e., no target language translation being provided.
                </p>
            </div>
        </section>
        
        <section class="mb-8">
            <h2 class="section-header text-2xl font-bold mb-4 text-slate-800 dark:text-slate-200 cursor-pointer hover:text-blue-600 dark:hover:text-blue-400 select-none">3. Methodology</h2>
            <div class="section-content">
                <p class="text-base leading-relaxed text-slate-700 dark:text-slate-300 mb-4">
                    Based on the analysis above, we propose a simple yet effective method to enhance LLMs' MT by explicitly indicating CSUs to provide meta-cognitive guidance. We first introduce the "semantic ambiguity" phenomenon in LLM's MT process. Inspired by this observation, an effective and light framework is designed to alleviate the influence of "semantic ambiguity", thereby improving the overall performance of MT.
                </p>
                <h3 class="text-lg font-semibold mb-3 text-slate-800 dark:text-slate-200">3.1 Semantic confusion</h3>
                <p class="text-base leading-relaxed text-slate-700 dark:text-slate-300 mb-4">
                    Current prompt-based MT paradigms for LLMs exhibit critical brittleness when processing sentences containing CSUs, as empirically evidenced by our preliminary analysis. The definition of CSUs in this paper is as follows: words with complex semantics or words that are uncommon to the model, such as polysemous words, domain-specific terms, and others. The common feature of CSUs is that they are highly sensitive to context, and may present semantic distinctions with a wide gap as the context varies.
                </p>
                <h3 class="text-lg font-semibold mb-3 text-slate-800 dark:text-slate-200">3.2 Dynamic Focus Anchoring (DFA) Method</h3>
                <p class="text-base leading-relaxed text-slate-700 dark:text-slate-300 mb-4">
                    Drawing upon the observed semantic ambiguity problem, we propose a simple but effective method, denoted as Dynamic Focus Anchoring (DFA) method. Our method contains two main steps: CSUs identification and semantic focus injection. The detection of CSUs is the first and fundamental step of the DFA method. However, CSU detection is often based on prior knowledge, such as semantic confusion datasets. Unfortunately, such datasets are scarce and difficult to obtain, making it challenging to support the multilingual MT requirements. To address this, we have developed a dual-layer semantic exploration mechanism: a bidirectional coupling framework that combines external prior knowledge guidance with internal knowledge activation, enabling the precise identification of translation-sensitive points.
                </p>
            </div>
        </section>
        
        <section class="mb-8">
            <h2 class="section-header text-2xl font-bold mb-4 text-slate-800 dark:text-slate-200 cursor-pointer hover:text-blue-600 dark:hover:text-blue-400 select-none">4. Experimental Setup</h2>
            <div class="section-content">
                <p class="text-base leading-relaxed text-slate-700 dark:text-slate-300 mb-4">
                    Detailed experimental setup in this paper is provided here. We follow standard MT setup, as implemented in previous work. Our method is evaluated on both sides of similar language pair English-German (EN-DE) and distant language pair English-Chinese (EN-ZH).
                </p>
                <h3 class="text-lg font-semibold mb-3 text-slate-800 dark:text-slate-200">Datasets</h3>
                <p class="text-base leading-relaxed text-slate-700 dark:text-slate-300 mb-4">
                    We evaluate the translation performance on the WMT22 test set, which covers domains such as news, social, e-commerce, and conversation. The bilingual lexicon used for extracting polysemous CSUs is the publicly available landing lexicon of MUSE, which gives as many translations of a source word as possible. The proposed method does not have a model training process and therefore does not involve training data.
                </p>
                <h3 class="text-lg font-semibold mb-3 text-slate-800 dark:text-slate-200">Backbone Models</h3>
                <p class="text-base leading-relaxed text-slate-700 dark:text-slate-300 mb-4">
                    We employ Llama2-7b and Llama3-8b as our backbone models. The maximum text length is 256. Beam Search is set to 5.
                </p>
                <h3 class="text-lg font-semibold mb-3 text-slate-800 dark:text-slate-200">Evaluation metrics</h3>
                <p class="text-base leading-relaxed text-slate-700 dark:text-slate-300 mb-4">
                    In this paper, several widely used machine translation evaluation metrics are employed to assess the effectiveness of the proposed method, including the classic BLEU score, the COMET scores which are more suitable for evaluating LLM-based translations, and ChrF2. For the translations provided by LLMs, the first sentence is retained as the final translation result for evaluation.
                </p>
            </div>
        </section>
        
        <section class="mb-8">
            <h2 class="section-header text-2xl font-bold mb-4 text-slate-800 dark:text-slate-200 cursor-pointer hover:text-blue-600 dark:hover:text-blue-400 select-none">5. Results and Discussion</h2>
            <div class="section-content">
                <p class="text-base leading-relaxed text-slate-700 dark:text-slate-300 mb-4">
                    In this section, we empirically demonstrate the effectiveness of our method in MT with LLMs scenario, including the main experiments, ablation study, evaluation with other metrics, polysemy analysis, hyperparameter analysis, and case study.
                </p>
                <h3 class="text-lg font-semibold mb-3 text-slate-800 dark:text-slate-200">5.1 Main Results</h3>
                <p class="text-base leading-relaxed text-slate-700 dark:text-slate-300 mb-4">
                    The main experimental results are presented in Table 3. Overall, the proposed method shows an average improvement of 0.83 and 0.81 in COMET and BLEU scores, respectively, compared to the most SOTA baseline system, Bayling2. This demonstrates a significant improvement in the MT task, and notably, our approach does not require model fine-tuning or the introduction of parallel sentence-level machine translation corpora.
                </p>
                <h3 class="text-lg font-semibold mb-3 text-slate-800 dark:text-slate-200">5.2 Ablation Study</h3>
                <p class="text-base leading-relaxed text-slate-700 dark:text-slate-300 mb-4">
                    A key contribution of our work is the extraction of CSUs and the focus on these units for targeted reasoning. To validate the effectiveness of the proposed method, we conducted an ablation experiment in which we tested the method's accuracy by considering each of the three types of CSUs separately.
                </p>
            </div>
        </section>
        
        <section class="mb-8">
            <h2 class="section-header text-2xl font-bold mb-4 text-slate-800 dark:text-slate-200 cursor-pointer hover:text-blue-600 dark:hover:text-blue-400 select-none">6. Related Work</h2>
            <div class="section-content">
                <p class="text-base leading-relaxed text-slate-700 dark:text-slate-300 mb-4">
                    Currently, research on enhancing LLM-based MT is primarily divided into two main categories: prompt engineering and instruction fine-tuning. Prompt engineering focuses on designing and finding suitable prompt templates, optimizing the bridge between the task and the LLMs to generate better translation results. One of the most representative works utilizes bilingual parallel pairs to address rare words in the source sentence, aiming to achieve improved translation results. Another approach, based on few-shot prompting, enhances LLMs' translation performance by providing source sentences and their parallel translations that are contextually similar to boost the translation quality. Instruction fine-tuning enhances the model's understanding of task-specific instructions, enabling it to produce results that are more aligned with human needs. This approach involves model training, and thus requires certain resources and time.
                </p>
            </div>
        </section>
        
        <section class="mb-8">
            <h2 class="section-header text-2xl font-bold mb-4 text-slate-800 dark:text-slate-200 cursor-pointer hover:text-blue-600 dark:hover:text-blue-400 select-none">7. Conclusion</h2>
            <div class="section-content">
                <p class="text-base leading-relaxed text-slate-700 dark:text-slate-300 mb-4">
                    In this study, we propose an effective method DFA to enhance LLM's MT ability based on dynamic focus anchoring and injecting. The semantic confusion problem is noticed, and is alleviated by analysis hard translated words (CSUs) and inject related focuses into LLMs. Two ways to obtain the CSUs are provided, namely, from external lexical data and LLMs internal knowledge activation, both can be used flexibly in a variety of application scenarios. Extensive experiments demonstrate the effectiveness and robustness of DFA across diverse experimental languages. Overall, our work presents a novel method for LLM-based MT, alleviating semantic confusion and offering promising results. Focusing on the CSUs helps LLMs to accurately retrieve the knowledge related to the translation focus and incorporate it into the translation process, leading to the generation of high-quality translations without model training.
                </p>
            </div>
        </section>
        
        <section class="mb-8">
            <h2 class="section-header text-2xl font-bold mb-4 text-slate-800 dark:text-slate-200 cursor-pointer hover:text-blue-600 dark:hover:text-blue-400 select-none">Limitation</h2>
            <div class="section-content">
                <p class="text-base leading-relaxed text-slate-700 dark:text-slate-300 mb-4">
                    Our work still has some limitations: 1) This study tests the impact of three types of challenging vocabulary on machine translation in the LLMs context. Additional types of challenging vocabulary can be analyzed and integrated into the method to achieve even better results. 2) The issue of semantic confusion also exists in other NLP tasks, such as dialogue systems. The proposed method can be extended in other NLP tasks to determine whether it leads to performance improvements, which might yield surprising results.
                </p>
            </div>
        </section>
        
        <section class="mb-8">
            <h2 class="section-header text-2xl font-bold mb-4 text-slate-800 dark:text-slate-200 cursor-pointer hover:text-blue-600 dark:hover:text-blue-400 select-none">Ethics Statement</h2>
            <div class="section-content">
                <p class="text-base leading-relaxed text-slate-700 dark:text-slate-300 mb-4">
                    Machine translation stands as a pivotal task within the realm of cross-lingual NLP, boasting a broad range of applications. Our experimental approach underscores diversity by encompassing three different languages. We aim to bridge modern NLP advancements with different languages. The MT dataset utilized in our research is openly accessible. We affirm that, to the best of our knowledge, no sensitive information is disclosed, and no foreseeable risks are associated with this work.
                </p>
            </div>
        </section>
        
        <section class="mb-8">
            <h2 class="section-header text-2xl font-bold mb-4 text-slate-800 dark:text-slate-200 cursor-pointer hover:text-blue-600 dark:hover:text-blue-400 select-none">References</h2>
            <div class="section-content">
                <p class="text-base leading-relaxed text-slate-700 dark:text-slate-300 mb-4">
                    SÃ©bastien Bubeck, Varun Chandrasekaran, Ronen Eldan, Johannes Gehrke, Eric Horvitz, Ece Kamar, Peter Lee, Yin Tat Lee, Yuanzhi Li, Scott Lundberg, Harsha Nori, Hamid Palangi, Marco Tulio Ribeiro, and Yi Zhang. 2023. Sparks of artificial general intelligence: Early experiments with gpt4. Preprint, arXiv:2303.12712.
                </p>
                <p class="text-base leading-relaxed text-slate-700 dark:text-slate-300 mb-4">
                    Hyunsoo Cho, Hyuhng Joon Kim, Junyeob Kim, SangWoo Lee, Sang-goo Lee, Kang Min Yoo, and Taeuk Kim. 2023. Prompt-augmented linear probing: Scaling beyond the limit of few-shot in-context learners. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 37, pages 12709â€“12718.
                </p>
                <p class="text-base leading-relaxed text-slate-700 dark:text-slate-300 mb-4">
                    Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William Fedus, Yunxuan Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, Albert Webson, Shixiang Shane Gu, Zhuyun Dai, Mirac Suzgun, Xinyun Chen, Aakanksha Chowdhery, Alex Castro-Ros, Marie Pellat, Kevin Robinson, Dasha Valter, Sharan Narang, Gaurav Mishra, Adams Yu, Vincent Zhao, Yanping Huang, Andrew Dai, Hongkun Yu, Slav Petrov, Ed H. Chi, Jeff Dean, Jacob Devlin, Adam Roberts, Denny Zhou, Quoc V. Le, and Jason Wei. 2024. Scaling instruction-finetuned language models. Journal of Machine Learning Research, 25(70):1â€“53.
                </p>
            </div>
        </section>
        
        <section class="mb-8">
            <h2 class="section-header text-2xl font-bold mb-4 text-slate-800 dark:text-slate-200 cursor-pointer hover:text-blue-600 dark:hover:text-blue-400 select-none">Appendix</h2>
            <div class="section-content">
                <p class="text-base leading-relaxed text-slate-700 dark:text-slate-300 mb-4">
                    In this section, we provide some technical details.
                </p>
                <h3 class="text-lg font-semibold mb-3 text-slate-800 dark:text-slate-200">A.1 Languages in MT Evaluation</h3>
                <p class="text-base leading-relaxed text-slate-700 dark:text-slate-300 mb-4">
                    A list of languages used in our experiment and their ISO 639-1 code.
                </p>
                <h3 class="text-lg font-semibold mb-3 text-slate-800 dark:text-slate-200">A.2 Prompt Template</h3>
                <p class="text-base leading-relaxed text-slate-700 dark:text-slate-300 mb-4">
                    The prompt template used in this paper follows one of the most SOTA LLMs in machine translation tasks: Bayling2.
                </p>
            </div>
        </section>
        
    </main>
    
    <script src="../script.js"></script>
</body>
</html> 