<!DOCTYPE html>
<html lang="en" data-theme="light">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Document Digest Template</title>
    
    <!-- Tailwind CSS Play CDN -->
    <script src="https://cdn.tailwindcss.com"></script>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:ital,opsz,wght@0,14..32,100..900;1,14..32,100..900&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="../styles.css">
    <script>
        tailwind.config = {
            darkMode: 'class',
        }
    </script>
</head>
<body class="bg-white dark:bg-slate-900 text-slate-800 dark:text-slate-200 transition-colors">
    
    <!-- Progress Bar -->
    <div class="progress-bar fixed top-0 left-0 h-1 bg-blue-500 z-50 transition-all duration-100"></div>
    
    <!-- Reading Time Display -->
    <div id="readingTimeDisplay" class="fixed top-2 left-4 px-3 py-1 bg-slate-100 dark:bg-slate-800 border border-slate-300 dark:border-slate-600 rounded-full text-xs text-slate-600 dark:text-slate-400 z-50 transition-colors">
        <span id="readingTimeText">📖 Calculating...</span>
    </div>
    
    <!-- Dark Mode Toggle -->
    <button id="themeToggle" class="fixed top-4 right-4 w-12 h-12 rounded-full bg-slate-100 dark:bg-slate-800 border border-slate-300 dark:border-slate-600 hover:bg-slate-200 dark:hover:bg-slate-700 flex items-center justify-center text-xl z-50 transition-colors">
        <span id="themeIcon">🌙</span>
    </button>
    
    <!-- Table of Contents -->
    <div class="toc-container fixed top-0 right-0 h-screen w-72 bg-slate-50 dark:bg-slate-800 border-l border-slate-200 dark:border-slate-700 z-40 overflow-y-auto">
        <div class="absolute -left-10 top-1/2 -translate-y-1/2 w-10 h-15 bg-slate-50 dark:bg-slate-800 border border-r-0 border-slate-200 dark:border-slate-700 rounded-l-lg flex items-center justify-center cursor-pointer text-slate-600 dark:text-slate-400">
            ☰
        </div>
        <div class="p-4">
            <h3 class="text-lg font-bold mb-4 text-slate-800 dark:text-slate-200">Contents</h3>
            <nav id="tocNav" class="space-y-2">
                <!-- TOC will be generated by JavaScript -->
            </nav>
        </div>
    </div>
    
    <!-- Main Content -->
    <main class="max-w-none mx-auto px-6 py-8" style="max-width: 70ch;">
        
        <!-- Prefix Panel -->
        <section class="bg-blue-50 dark:bg-blue-950 border-l-4 border-blue-400 dark:border-blue-500 p-4 rounded-r-lg mb-8">
            <h2 class="section-header text-xl font-semibold mb-3 text-slate-800 dark:text-slate-200 cursor-pointer hover:text-blue-600 dark:hover:text-blue-400 select-none">📋 How This Document Was Created</h2>
            <div class="section-content">
                <p class="text-sm text-slate-600 dark:text-slate-400 mb-2">
                    This document represents a condensed version of a longer work, transformed into an interactive web format. Here's what was retained, condensed, or omitted:
                </p>
                <ul class="text-sm text-slate-600 dark:text-slate-400 space-y-1 ml-4">
                    <li><strong>Retained:</strong> Core arguments, key insights, and main conclusions</li>
                    <li><strong>Condensed:</strong> Complex details simplified for broader accessibility</li>
                    <li><strong>Omitted:</strong> Repetitive sections, extensive citations, and tangential content</li>
                </ul>
            </div>
        </section>
        
        <!-- Document Summary -->
        <section class="mb-8">
            <h2 class="section-header text-2xl font-bold mb-4 text-slate-800 dark:text-slate-200 cursor-pointer hover:text-blue-600 dark:hover:text-blue-400 select-none">📄 Summary</h2>
            <div class="section-content">
                <p class="text-lg leading-relaxed text-slate-700 dark:text-slate-300 mb-4">
                    Scientific research is inherently global. However, the vast majority of academic journals are published exclusively in English, creating barriers for non-native-English-speaking researchers. In this study, we leverage large language models (LLMs) to translate published scientific articles while preserving their native JATS XML formatting, thereby developing a practical, automated approach for implementation by academic journals.
                </p>
                <p class="text-lg leading-relaxed text-slate-700 dark:text-slate-300 mb-4">
                    Using our approach, we translate articles across multiple scientific disciplines into 28 languages. To evaluate translation accuracy, we introduce a novel question-and-answer (QA) benchmarking method, in which an LLM generates comprehension-based questions from the original text and then answers them based on the translated text. Our benchmark results show an average performance of 95.9%, showing that the key scientific details are accurately conveyed.
                </p>
                <p class="text-lg leading-relaxed text-slate-700 dark:text-slate-300 mb-4">
                    In a user study, we translate the scientific papers of 15 researchers into their native languages, finding that the authors consistently found the translations to accurately capture the original information in their articles. Interestingly, a third of the authors found many technical terms "overtranslated," expressing a preference to keep terminology more familiar in English untranslated.
                </p>
                <p class="text-lg leading-relaxed text-slate-700 dark:text-slate-300">
                    Finally, we demonstrate how in-context learning techniques can be used to align translations with domain-specific preferences such as mitigating overtranslation, highlighting the adaptability and utility of LLM-driven scientific translation.
                </p>
            </div>
        </section>
        
        <!-- Content Sections -->
        <section class="mb-8">
            <h2 class="section-header text-2xl font-bold mb-4 text-slate-800 dark:text-slate-200 cursor-pointer hover:text-blue-600 dark:hover:text-blue-400 select-none">1. Introduction</h2>
            <div class="section-content">
                <p class="text-base leading-relaxed text-slate-700 dark:text-slate-300 mb-4">
                    Around 98% of all peer-reviewed scientific articles are published in English, but only around 7% of the world's population speaks English as a first language. While having a common language among academic journals facilitates international scientific discourse, it also creates a significant barrier to access scientific knowledge for non-native English speakers.
                </p>
                
                <div class="bg-blue-50 dark:bg-blue-950 border-l-4 border-blue-400 dark:border-blue-500 p-4 rounded-r-lg mb-4">
                    <p class="text-sm text-blue-800 dark:text-blue-200">
                        <strong>Key Insight:</strong> 96% of respondents agree or strongly agree that English as the dominant academic language disproportionately advantages native speakers. This linguistic dominance introduces challenges across multiple aspects of science, from biases in peer review against non-native English writers to global implications for science-informed policy.
                    </p>
                </div>

                <p class="text-base leading-relaxed text-slate-700 dark:text-slate-300 mb-4">
                    At the heart of this issue is language accessibility in existing scientific literature. Academic journals, especially widely-read and open-access journals, cater to a global audience. The availability of scientific literature in a person's native language could play a crucial role in shaping their decision to pursue a career in science.
                </p>

                <p class="text-base leading-relaxed text-slate-700 dark:text-slate-300 mb-4">
                    Machine translation offers a cost-effective and scalable solution for translating text. With the rapid development of neural-based approaches and deep learning, machine translation improved enormously, and neural machine translation (NMT) systems like Google Translate and DeepL have been the gold standard for both general and professional translation tasks.
                </p>

                <p class="text-base leading-relaxed text-slate-700 dark:text-slate-300 mb-4">
                    Recently, with the rise of transformer-based large language models (LLMs), the landscape is shifting. Recent studies show that LLMs match and often surpass NMT systems in performance across a wide variety of translation tasks, including scientific text. What truly sets LLMs apart, however, is their ability to process complex instructions and generate context-aware, customized outputs.
                </p>

                <h3 class="text-lg font-semibold mb-3 text-slate-800 dark:text-slate-200">1.1 Related Works</h3>
                <p class="text-base leading-relaxed text-slate-700 dark:text-slate-300 mb-4">
                    Several studies have evaluated the performance of LLMs (e.g. GPT models) on various translation tasks, showing that many are competitive with previous state of the art NMT systems, especially more recent models such as GPT-4. Further developments in LLM-based translation include prompting techniques, context aware and document-level translation, translations that adapt to user feedback in real time, non-English monolingual corpora fine-tuning, and fine-tuning to emulate professional human translation strategies.
                </p>

                <div class="bg-amber-50 dark:bg-amber-950 border-l-4 border-amber-400 dark:border-amber-500 p-4 rounded-r-lg mb-4">
                    <p class="text-sm text-amber-800 dark:text-amber-200">
                        <strong>Research Gap:</strong> When it comes to assessing machine translation of scientific journal articles, the literature is more sparse. Most existing studies focus on medical texts or scientific abstracts, but the topic of translating full-length academic journal articles has yet to be thoroughly investigated.
                    </p>
                </div>

                <h3 class="text-lg font-semibold mb-3 text-slate-800 dark:text-slate-200">1.2 Our Contributions</h3>
                <ul class="list-disc list-inside space-y-2 text-slate-700 dark:text-slate-300 ml-4 mb-4">
                    <li><strong>Journal-compatible translation:</strong> We develop the first pipeline using LLMs to translate scientific articles while preserving standard publishing formats (JATS XML).</li>
                    <li><strong>Automated QA benchmarking:</strong> We have developed an automated benchmarking method specifically tailored for scientific documents that requires only the original and translated documents to assess translation quality.</li>
                    <li><strong>Translation preferences for scientific text:</strong> We have gathered feedback on machine translations in a variety of languages directly from authors of research papers across multiple scientific disciplines.</li>
                </ul>
            </div>
        </section>
        
        <!-- Add more sections by copying the template above -->
        
        <!-- Glossary -->
        <section class="mb-8">
            <h2 class="section-header text-2xl font-bold mb-4 text-slate-800 dark:text-slate-200 cursor-pointer hover:text-blue-600 dark:hover:text-blue-400 select-none">📚 Glossary</h2>
            <div class="section-content">
                <div class="grid grid-cols-1 md:grid-cols-2 gap-4">
                    <!-- Copy this template for each glossary term -->
                    <div class="bg-slate-50 dark:bg-slate-800 p-3 rounded-lg border border-slate-200 dark:border-slate-700">
                        <h4 class="font-semibold text-slate-800 dark:text-slate-200">[Term]</h4>
                        <p class="text-sm text-slate-600 dark:text-slate-400">[Definition - keep it concise and clear]</p>
                    </div>
                    <!-- Add more terms as needed -->
                </div>
            </div>
        </section>
        
        <section class="mb-8">
            <h2 class="section-header text-2xl font-bold mb-4 text-slate-800 dark:text-slate-200 cursor-pointer hover:text-blue-600 dark:hover:text-blue-400 select-none">2. Journal-compatible Translation</h2>
            <div class="section-content">
                <p class="text-base leading-relaxed text-slate-700 dark:text-slate-300 mb-4">
                    Journals have the power to change language barrier norms, as they serve as the primary forum for scientific knowledge. However, for multilingual translation to be widely adopted in scientific publishing, the process must be practical for journals to implement. In this section, we demonstrate how LLMs can preserve the formatting of journal articles during translation, offering an approach that is adaptable and easy to integrate.
                </p>

                <div class="bg-blue-50 dark:bg-blue-950 border-l-4 border-blue-400 dark:border-blue-500 p-4 rounded-r-lg mb-4">
                    <p class="text-sm text-blue-800 dark:text-blue-200">
                        <strong>Key Standard:</strong> In 2002, the NIH introduced the Journal Article Tag Suite (JATS), an XML protocol for structuring scientific journal articles. Since then, JATS has become part of the National Information Standards Organization (NISO) and is the global standard for academic publishing. Despite the distinct "look and feel" of articles across different publishers, they all share the same underlying JATS XML structure.
                    </p>
                </div>

                <p class="text-base leading-relaxed text-slate-700 dark:text-slate-300 mb-4">
                    We employ an LLM (GPT-4o) to translate journal articles in their native JATS form, ensuring that the XML structure remains intact while translating the content. When tasked with translating a section, GPT-4o successfully translates the text while preserving the surrounding XML tags. A full article is much more complex, however, consisting of multiple, heavily nested elements that include figures, tables, equations, and more.
                </p>

                <p class="text-base leading-relaxed text-slate-700 dark:text-slate-300 mb-4">
                    We translate each full article in a series of API calls to GPT-4o, processing memory-manageable chunks (typically around 5 paragraphs) at a time. To increase context awareness, we prepend the prompt with the contents of the full original document.
                </p>

                <div class="bg-green-50 dark:bg-green-950 border-l-4 border-green-400 dark:border-green-500 p-4 rounded-r-lg mb-4">
                    <p class="text-sm text-green-800 dark:text-green-200">
                        <strong>Results:</strong> In the 348 translations we generated over the course of this study, we identified no truncation errors and only one nesting error, resulting in a 99.7% accuracy in preserving the original JATS structures.
                    </p>
                </div>

                <p class="text-base leading-relaxed text-slate-700 dark:text-slate-300 mb-4">
                    Using our method, we successfully translate full articles into 28 different languages while fully preserving the JATS formatting. Because of its compatibility with native article formatting, this translation step can be applied at the final stage of publication or to articles that have already been published. This ensures maximum compatibility with the publication framework and paves the way for widespread translation of articles across different journals.
                </p>

                <p class="text-base leading-relaxed text-slate-700 dark:text-slate-300">
                    Moreover, the translation is applicable to an arbitrary number of languages. While JATS is the ubiquitous standard, this approach is adaptable to other XML protocols as long as the tag suite is properly documented, ensuring broad compatibility across scientific publishing.
                </p>
            </div>
        </section>
        
        <section class="mb-8">
            <h2 class="section-header text-2xl font-bold mb-4 text-slate-800 dark:text-slate-200 cursor-pointer hover:text-blue-600 dark:hover:text-blue-400 select-none">3. QA-style Automated Benchmarking</h2>
            <div class="section-content">
                <p class="text-base leading-relaxed text-slate-700 dark:text-slate-300 mb-4">
                    In this section, we evaluate the translation quality of our approach. Traditional machine translation evaluation relies on automated benchmarking metrics such as BLEU, which compare translations against parallel reference data. However, to our knowledge, no dataset exists that provides parallel, document-level scientific translations across the diverse range of languages and disciplines we have included here.
                </p>

                <p class="text-base leading-relaxed text-slate-700 dark:text-slate-300 mb-4">
                    Instead, we introduce a novel question-and-answer (QA) style benchmarking method. In this approach, an LLM generates a "quiz" with multiple-choice questions designed to capture key details from the original scientific article. The LLM then "reads" the translated article and attempts to answer these questions based solely on the translated content. The higher the accuracy, the better the translation conveys the scientific details of the original text.
                </p>

                <div class="bg-purple-50 dark:bg-purple-950 border-l-4 border-purple-400 dark:border-purple-500 p-4 rounded-r-lg mb-4">
                    <p class="text-sm text-purple-800 dark:text-purple-200">
                        <strong>Key Advantage:</strong> Unlike traditional evaluation techniques, our benchmarking method does not require parallel translation data and is therefore applicable to any article, in any format, and in any language. This flexibility is particularly valuable for evaluating translations in "low-resource" languages, where high-quality parallel datasets are scarce.
                    </p>
                </div>

                <h3 class="text-lg font-semibold mb-3 text-slate-800 dark:text-slate-200">3.1 Benchmarking Procedure</h3>
                <p class="text-base leading-relaxed text-slate-700 dark:text-slate-300 mb-4">
                    First, we prepare the quiz by providing GPT-4o with the original English text and prompting it to create 50 multiple-choice questions that encapsulate key details of the paper, along with a corresponding answer key. To execute the benchmark, we then prompt the model to read the translated article and answer the quiz questions.
                </p>

                <p class="text-base leading-relaxed text-slate-700 dark:text-slate-300 mb-4">
                    In this scenario, the model simulates a real person reading the translated text; if the translated article effectively conveys the core details and central findings, the model should perform well on the evaluation. The model's quiz accuracy, graded against the answer key, constitutes the benchmark result.
                </p>

                <p class="text-base leading-relaxed text-slate-700 dark:text-slate-300 mb-4">
                    To ensure that the quiz-taking LLM relies only on the translated article rather than its prior knowledge, we implement two safeguards:
                </p>
                <ul class="list-disc list-inside space-y-2 text-slate-700 dark:text-slate-300 ml-4 mb-4">
                    <li>We exclude the quiz-generation exchange from the model's memory before administering the quiz</li>
                    <li>We prevent pre-training contamination by filtering for articles that score 0% on the benchmark when the article is not provided</li>
                </ul>

                <h3 class="text-lg font-semibold mb-3 text-slate-800 dark:text-slate-200">3.2 Results</h3>
                <p class="text-base leading-relaxed text-slate-700 dark:text-slate-300 mb-4">
                    For this study, we apply the QA benchmark to six articles spanning a wide range of disciplines, from medicine to archaeology to quantum optics. Each article is evaluated across translations in 28 different languages, which were selected based on countries in Nature Index's Research Leaders list and further supplemented to include languages from more regions of the world.
                </p>

                <div class="bg-green-50 dark:bg-green-950 border-l-4 border-green-400 dark:border-green-500 p-4 rounded-r-lg mb-4">
                    <p class="text-sm text-green-800 dark:text-green-200">
                        <strong>Key Results:</strong> The overall average performance across all 29 languages and all six articles is 95.9%, with the lowest average score at 91.7% (Tamil) and the highest average score at 98.0% (Swedish). Notably, no individual quiz score falls below 84%, and translations in 23 languages score 100% on at least one article.
                    </p>
                </div>

                <p class="text-base leading-relaxed text-slate-700 dark:text-slate-300 mb-4">
                    The English baseline score (97.3%) is higher than the overall average, but not a perfect 100%. We attribute this to two potential factors: (1) the quiz-taking LLM, like a human reader, may exhibit slight imperfections in reading comprehension, and (2) quiz questions or answer choices may be occasionally ambiguous.
                </p>

                <p class="text-base leading-relaxed text-slate-700 dark:text-slate-300">
                    Additionally, our results reveal that "low-resource" languages such as Urdu, Telugu, and Tamil perform slightly below high-resource languages, aligning with prior findings in both machine translation and multilingual LLM research. However, since even the lowest-performing languages achieve an average accuracy above 91%, this effect is minor, demonstrating that our benchmarking technique is applicable across a wide range of languages.
                </p>
            </div>
        </section>
        
        <section class="mb-8">
            <h2 class="section-header text-2xl font-bold mb-4 text-slate-800 dark:text-slate-200 cursor-pointer hover:text-blue-600 dark:hover:text-blue-400 select-none">4. Feedback from Authors</h2>
            <div class="section-content">
                <p class="text-base leading-relaxed text-slate-700 dark:text-slate-300 mb-4">
                    In this section we complement the QA benchmarking results with evaluations from 15 human scientists across various languages and disciplines, including theoretical and experimental quantum optics, nanophotonics, biostatistics, materials science, magneto-electronics, machine learning, and more. In this study, each participant is provided with a translation of their own scientific paper in their native language, generated using our method.
                </p>

                <p class="text-base leading-relaxed text-slate-700 dark:text-slate-300 mb-4">
                    We gather feedback on translation quality using the following questions:
                </p>
                <ul class="list-disc list-inside space-y-2 text-slate-700 dark:text-slate-300 ml-4 mb-4">
                    <li>How effectively does the translation <strong>convey the original information</strong> of the article?</li>
                    <li>How well do you think another speaker of this language would be able to <strong>understand the key ideas</strong> of this paper just from this translation?</li>
                    <li>How satisfied are you with the translation of <strong>technical terms</strong> in the article?</li>
                    <li>How well does the translation <strong>flow and maintain cohesion</strong> throughout the text?</li>
                    <li>How well does the translation maintain the original <strong>tone and style</strong> of the article?</li>
                </ul>

                <p class="text-base leading-relaxed text-slate-700 dark:text-slate-300 mb-4">
                    For each question, the three possible options are "few or no issues", "some issues", "many issues", and "other". Participants also have the opportunity to provide free-form comments with their observations and opinions.
                </p>

                <div class="bg-green-50 dark:bg-green-950 border-l-4 border-green-400 dark:border-green-500 p-4 rounded-r-lg mb-4">
                    <p class="text-sm text-green-800 dark:text-green-200">
                        <strong>Key Results:</strong> Nearly all researchers in our study (93.3%) report that the translation of their paper contains "few or no issues" in conveying the original information, reinforcing the findings from our QA benchmarking. Participants also generally agree (86.7%) that other scientists reading their translated paper would understand the key ideas with "few or no issues".
                    </p>
                </div>

                <p class="text-base leading-relaxed text-slate-700 dark:text-slate-300 mb-4">
                    Key insights arise from the more subjective questions. As one might anticipate from machine translation, authors rate lower scores in the categories of tone and style, flow and cohesion, and technical terms. In particular, many participants (86.7%) describe an unnatural quality to the translation or dissatisfaction attributed to the handling of technical and domain-specific vocabulary.
                </p>

                <p class="text-base leading-relaxed text-slate-700 dark:text-slate-300 mb-4">
                    With regard to technical vocabulary, participants reported two kinds of issues:
                </p>

                <h3 class="text-lg font-semibold mb-3 text-slate-800 dark:text-slate-200">Mistranslation</h3>
                <p class="text-base leading-relaxed text-slate-700 dark:text-slate-300 mb-4">
                    This occurs when a technical term exists in their native language, but the model translated it awkwardly or incorrectly. For example:
                </p>
                <ul class="list-disc list-inside space-y-2 text-slate-700 dark:text-slate-300 ml-4 mb-4">
                    <li>The model translated "edge coupling" into French as "couplage par bord", but the more commonly-used phrase is "couplage par la tranche"</li>
                    <li>The model translated "switching" (e.g. magnetic switching) into Chinese as "切換", but "轉換" is a better fit</li>
                </ul>

                <h3 class="text-lg font-semibold mb-3 text-slate-800 dark:text-slate-200">Overtranslation</h3>
                <p class="text-base leading-relaxed text-slate-700 dark:text-slate-300 mb-4">
                    This occurs when a technical term does not exist in their native language, or is rarely used in practice, and the original English word is preferred. For example:
                </p>
                <ul class="list-disc list-inside space-y-2 text-slate-700 dark:text-slate-300 ml-4 mb-4">
                    <li>The model provided a literal translation of "rigorous coupled-wave analysis" into Korean (엄밀 결합 파동 해석), but using the English term is preferred</li>
                    <li>The model translated "gap" (e.g. Hamiltonian/energetic gap) into Spanish as "brecha" (breach). A better translation might be "salto", as in "salto de energía" (energy jump), but many scientists would simply use the English "gap"</li>
                </ul>

                <div class="bg-amber-50 dark:bg-amber-950 border-l-4 border-amber-400 dark:border-amber-500 p-4 rounded-r-lg">
                    <p class="text-sm text-amber-800 dark:text-amber-200">
                        <strong>Important Finding:</strong> Whether certain terms might be more appropriately left untranslated is not a typical factor in traditional machine translation. However, the feedback from scientists highlights the importance of this consideration in scientific translation. The frequency of overtranslation comments in our survey responses (33.3%) suggests the need for nuanced translation approaches that align with how technical terms are used in practice.
                    </p>
                </div>
            </div>
        </section>
        
        <section class="mb-8">
            <h2 class="section-header text-2xl font-bold mb-4 text-slate-800 dark:text-slate-200 cursor-pointer hover:text-blue-600 dark:hover:text-blue-400 select-none">5. Feedback-adaptive Translation</h2>
            <div class="section-content">
                <p class="text-base leading-relaxed text-slate-700 dark:text-slate-300 mb-4">
                    In this section, we leverage LLM output customization to incorporate the feedback from scientists. In particular, since so many scientists expressed a preference for retaining some technical terms in English, we apply a targeted prompting technique to preserve some English vocabulary during translation.
                </p>

                <p class="text-base leading-relaxed text-slate-700 dark:text-slate-300 mb-4">
                    To translate text while maintaining the appropriate English terms, a key challenge is the inherently subjective nature of deciding which terms to keep and which to translate. To navigate this, we employ few-shot prompting, an in-context learning technique where GPT-4o is provided with verified examples to improve responses in scenarios where data is scarce.
                </p>

                <p class="text-base leading-relaxed text-slate-700 dark:text-slate-300 mb-4">
                    Specifically, we construct a one-shot prompt using a translated paragraph from a scientific article in which the author of the article has reviewed the translation and identified terms that should remain in English. This curated example then serves as a guide for translating other texts.
                </p>

                <div class="bg-blue-50 dark:bg-blue-950 border-l-4 border-blue-400 dark:border-blue-500 p-4 rounded-r-lg mb-4">
                    <p class="text-sm text-blue-800 dark:text-blue-200">
                        <strong>Methodology:</strong> Using this prompting method, we generate new translations and seek feedback from five authors who previously expressed concerns about technical term translations. Each participant reviews two versions of an excerpt from their paper: one direct translation and one generated with the one-shot prompt that retains some English terms.
                    </p>
                </div>

                <h3 class="text-lg font-semibold mb-3 text-slate-800 dark:text-slate-200">Results and Insights</h3>
                <p class="text-base leading-relaxed text-slate-700 dark:text-slate-300 mb-4">
                    The results of this follow-up survey reveal a diverse range of preferences:
                </p>
                <ul class="list-disc list-inside space-y-2 text-slate-700 dark:text-slate-300 ml-4 mb-4">
                    <li>Three of five participants find that retaining some English terms produces a more natural and readable scientific text</li>
                    <li>The other two participants are more inclined toward the complete translation, citing a preference for better-translated terms over English terms</li>
                    <li>One participant proposes a balanced approach: to present the original English term in brackets alongside the translated word, rather than strictly choosing one over the other</li>
                </ul>

                <div class="bg-purple-50 dark:bg-purple-950 border-l-4 border-purple-400 dark:border-purple-500 p-4 rounded-r-lg mb-4">
                    <p class="text-sm text-purple-800 dark:text-purple-200">
                        <strong>Interesting Observation:</strong> Speakers of languages with a higher prevalence of English loanwords, such as Korean, tend to favor English technical terms compared to those from languages with fewer English loanwords, such as French, a phenomenon which might be influenced by historical linguistic reasons.
                    </p>
                </div>

                <p class="text-base leading-relaxed text-slate-700 dark:text-slate-300">
                    The strength of LLM-based translation lies in its ability to integrate diverse customization and feedback, enabling tailored and therefore more effective translations. While this study focuses on the overtranslation phenomenon, the prompting technique we utilize in this section can be applied further to other vocabulary or stylistic preferences by incorporating additional examples.
                </p>
            </div>
        </section>
        
        <section class="mb-8">
            <h2 class="section-header text-2xl font-bold mb-4 text-slate-800 dark:text-slate-200 cursor-pointer hover:text-blue-600 dark:hover:text-blue-400 select-none">6. Discussion</h2>
            <div class="section-content">
                <p class="text-base leading-relaxed text-slate-700 dark:text-slate-300 mb-4">
                    In this study, we utilized LLM-powered translation to go beyond traditional plain-text translation, resulting in scientific translations that are tailored with both publishers and authors in mind. Our method successfully translates scientific articles in JATS XML while maintaining the complex structure, opening a new avenue for academic journals to include translations for their articles.
                </p>

                <p class="text-base leading-relaxed text-slate-700 dark:text-slate-300 mb-4">
                    Through a novel automated QA benchmarking approach, we quantitatively evaluated full article translations across 28 languages and many scientific disciplines, finding that key scientific details are reliably conveyed even in low-resource languages. Further, our human evaluation study revealed valuable insights into the qualitative aspects of scientific translation.
                </p>

                <div class="bg-green-50 dark:bg-green-950 border-l-4 border-green-400 dark:border-green-500 p-4 rounded-r-lg mb-4">
                    <p class="text-sm text-green-800 dark:text-green-200">
                        <strong>Key Achievement:</strong> While the survey results confirmed the high overall translation accuracy, they also highlighted areas for improvement, such as the handling of technical vocabulary. By leveraging the few-shot prompting technique, we incorporated feedback and generate customized translations that align with the linguistic preferences of researchers across different fields and languages.
                    </p>
                </div>

                <p class="text-base leading-relaxed text-slate-700 dark:text-slate-300 mb-4">
                    Ultimately, our findings emphasize that the flexibility of LLMs allows for nearly limitless degrees of customizability, making it possible to improve translations based on domain-specific requirements and preferences. This adaptability presents a significant step toward breaking language barriers in academic publishing, fostering broader accessibility and collaboration in global research.
                </p>

                <h3 class="text-lg font-semibold mb-3 text-slate-800 dark:text-slate-200">6.1 Limitations and Future Directions</h3>
                <p class="text-base leading-relaxed text-slate-700 dark:text-slate-300 mb-4">
                    Two participants in our user study reported inconsistencies in the translation of certain terms throughout the article. This likely stems from our approach of translating articles in separate sections to mitigate memory and XML nesting issues, leading to potential variations in the model's vocabulary choices between different API calls.
                </p>

                <p class="text-base leading-relaxed text-slate-700 dark:text-slate-300 mb-4">
                    Possible solutions and future directions include:
                </p>
                <ul class="list-disc list-inside space-y-2 text-slate-700 dark:text-slate-300 ml-4 mb-4">
                    <li>Track all translations of the same term and standardize them at the end by replacing inconsistent terms with the most common translation</li>
                    <li>Explore ways to enhance context-awareness in scientific translation, which may also help reduce vocabulary inconsistencies</li>
                    <li>Conduct further testing with other LLMs to provide valuable insights into their suitability for the translation methods introduced in this study</li>
                    <li>Expand on understanding researchers' preferences in scientific translation through larger-scale surveys</li>
                    <li>If our method is adopted for large-scale scientific translation, use the resulting corpora to fine-tune models, further improving consistency and overall translation quality</li>
                </ul>
            </div>
        </section>
        
        <section class="mb-8">
            <h2 class="section-header text-2xl font-bold mb-4 text-slate-800 dark:text-slate-200 cursor-pointer hover:text-blue-600 dark:hover:text-blue-400 select-none">References</h2>
            <div class="section-content">
                <ul class="list-none space-y-4 text-sm text-slate-700 dark:text-slate-300">
                    <li>Ahn, G. H., Amani, M., Rasool, H., Lien, D. H., Mastandrea, J. P., Ager III, J. W., ... & Javey, A. (2017). Strain-engineered growth of two-dimensional materials. <em>Nature communications</em>, 8(1), 608.</li>
                    <li>Blackwood, R. (2013). French, language policy and new media/französisch, sprachpolitiken und neue medien/le français, la politique linguistique et les nouveaux média. <em>Sociolinguistica</em>, 27(1), 37-53.</li>
                    <li>Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J. D., Dhariwal, P., ... & Amodei, D. (2020). Language models are few-shot learners. <em>Advances in neural information processing systems</em>, 33, 1877-1901.</li>
                    <li>Daniele, F. (2019). Performance of an automatic translator in translating medical abstracts. <em>Heliyon</em>, 5(10).</li>
                    <li>Faure, P. (2018). From accouchement to agony: a lexicological analysis of words of french origin in the modern english language of medicine. <em>Lexis. Journal in English Lexicology</em>, (11).</li>
                    <li>Ferguson, G., Pérez-Llantada, C., & Plo, R. (2011). English as an international language of scientific publication: A study of attitudes. <em>World Englishes</em>, 30(1), 41-59.</li>
                    <li>Fernández-Crespo, T., Ordoño, J., Etxeberria, F., Herrasti, L., Armendariz, A., Vegas, J. I., & Schulting, R. J. (2023). Large-scale violence in late neolithic western europe based on expanded skeletal evidence from san juan ante portam latinam. <em>Scientific Reports</em>, 13(1), 17103.</li>
                    <li>Flowerdew, J. (1999). Writing for scholarly publication in english: The case of hong kong. <em>Journal of Second Language Writing</em>, 8(2), 123-145.</li>
                    <li>He, Z., Liang, T., Jiao, W., Zhang, Z., Yang, Y., Wang, R., ... & Wang, X. (2024). Exploring human-like translation strategy with large language models. <em>Transactions of the Association for Computational Linguistics</em>, 12, 229-246.</li>
                </ul>
            </div>
        </section>
        
    </main>
    
    <script src="../script.js"></script>
</body>
</html> 