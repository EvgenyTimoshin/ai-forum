<!-- GPT Models Section -->
<h2 class="section-header text-2xl font-bold mb-4 text-slate-800 dark:text-slate-200 cursor-pointer hover:text-blue-600 dark:hover:text-blue-400 select-none">ðŸŒŸ OpenAI GPT Family: Diverse Models for Every Need</h2>
<div class="section-content">
    <p class="text-lg leading-relaxed text-slate-700 dark:text-slate-300 mb-4">
        OpenAI's 2025 lineup showcases a diverse range of models, each optimized for specific use cases and budget considerations <a href="#source2" class="no-audio text-blue-600 dark:text-blue-400 hover:underline">[2]</a>. From the flagship <strong>GPT-4.5 (o3)</strong> to the efficient <strong>o3-mini</strong>, the family offers solutions across the performance-cost spectrum.
    </p>
    
    <h3 class="text-xl font-semibold mb-3 text-slate-800 dark:text-slate-200">GPT-4.5 (o3) - The Premium Choice</h3>
    <div class="bg-purple-50 dark:bg-purple-950 p-4 rounded-lg border border-purple-200 dark:border-purple-700 mb-6">
        <ul class="space-y-2 text-slate-700 dark:text-slate-300">
            <li><strong><span class="glossary-term relative border-b border-dotted border-slate-400 cursor-help" data-definition="The maximum amount of text an LLM can process in a single request, measured in tokens. Larger windows enable processing of entire documents or codebases.">Context Window</span>:</strong> 256K <span class="glossary-term relative border-b border-dotted border-slate-400 cursor-help" data-definition="The basic unit of text processing in LLMs. Roughly equivalent to 0.75 words in English. API pricing is typically based on token consumption.">tokens</span></li>
            <li><strong>Pricing:</strong> $75 input / $150 output per million <span class="glossary-term relative border-b border-dotted border-slate-400 cursor-help" data-definition="The basic unit of text processing in LLMs. Roughly equivalent to 0.75 words in English. API pricing is typically based on token consumption.">tokens</span> - Premium tier pricing</li>
            <li><strong>Strengths:</strong> Natural conversation, high <span class="glossary-term relative border-b border-dotted border-slate-400 cursor-help" data-definition="A model's ability to understand and respond to human emotions appropriately, creating more natural and empathetic interactions.">emotional intelligence</span>, creative writing</li>
            <li><strong>Best For:</strong> Customer-facing applications, creative content, complex dialogue systems</li>
        </ul>
    </div>
    
    <h3 class="text-xl font-semibold mb-3 text-slate-800 dark:text-slate-200">GPT-4.1 - The Balanced Performer</h3>
    <div class="bg-indigo-50 dark:bg-indigo-950 p-4 rounded-lg border border-indigo-200 dark:border-indigo-700 mb-6">
        <ul class="space-y-2 text-slate-700 dark:text-slate-300">
            <li><strong><span class="glossary-term relative border-b border-dotted border-slate-400 cursor-help" data-definition="The maximum amount of text an LLM can process in a single request, measured in tokens. Larger windows enable processing of entire documents or codebases.">Context Window</span>:</strong> 1M <span class="glossary-term relative border-b border-dotted border-slate-400 cursor-help" data-definition="The basic unit of text processing in LLMs. Roughly equivalent to 0.75 words in English. API pricing is typically based on token consumption.">tokens</span> - Massive context for document processing</li>
            <li><strong><span class="glossary-term relative border-b border-dotted border-slate-400 cursor-help" data-definition="Software Engineering benchmark measuring LLM ability to solve real-world coding problems from GitHub issues. Higher scores indicate better coding capabilities.">SWE-bench</span> Score:</strong> 54.6% <a href="#source8" class="no-audio text-blue-600 dark:text-blue-400 hover:underline">[8]</a></li>
            <li><strong><span class="glossary-term relative border-b border-dotted border-slate-400 cursor-help" data-definition="The date after which an LLM has no training data. More recent cutoffs mean the model knows about more current events and developments.">Knowledge Cutoff</span>:</strong> June 2024</li>
            <li><strong>Strengths:</strong> <span class="glossary-term relative border-b border-dotted border-slate-400 cursor-help" data-definition="The ability of an LLM to interact with external services and APIs, enabling actions like web searches, code execution, or database queries within conversations.">Tool use</span> integration, natural conversation flow</li>
            <li><strong>Best For:</strong> Long document analysis, multi-turn conversations, <span class="glossary-term relative border-b border-dotted border-slate-400 cursor-help" data-definition="The ability of an LLM to interact with external services and APIs, enabling actions like web searches, code execution, or database queries within conversations.">tool-calling</span> workflows</li>
        </ul>
    </div>
    
    <h3 class="text-xl font-semibold mb-3 text-slate-800 dark:text-slate-200">GPT o3-mini - The Efficiency Champion</h3>
    <div class="bg-green-50 dark:bg-green-950 p-4 rounded-lg border border-green-200 dark:border-green-700 mb-6">
        <ul class="space-y-2 text-slate-700 dark:text-slate-300">
            <li><strong><span class="glossary-term relative border-b border-dotted border-slate-400 cursor-help" data-definition="The maximum amount of text an LLM can process in a single request, measured in tokens. Larger windows enable processing of entire documents or codebases.">Context Window</span>:</strong> 200K <span class="glossary-term relative border-b border-dotted border-slate-400 cursor-help" data-definition="The basic unit of text processing in LLMs. Roughly equivalent to 0.75 words in English. API pricing is typically based on token consumption.">tokens</span></li>
            <li><strong>Optimization:</strong> Specifically tuned for <span class="glossary-term relative border-b border-dotted border-slate-400 cursor-help" data-definition="Science, Technology, Engineering, and Mathematics problems that require analytical thinking, numerical computation, and domain-specific knowledge.">STEM tasks</span></li>
            <li><strong>Performance:</strong> Fast inference times with competitive accuracy</li>
            <li><strong>Best For:</strong> High-volume processing, mathematical computations, quick responses</li>
        </ul>
    </div>
    
    <h3 class="text-xl font-semibold mb-3 text-slate-800 dark:text-slate-200">Comparative Analysis</h3>
    <div class="overflow-x-auto mb-6">
        <table class="min-w-full bg-white dark:bg-slate-800 border border-slate-200 dark:border-slate-700 rounded-lg">
            <thead class="bg-slate-50 dark:bg-slate-700">
                <tr>
                    <th class="px-4 py-2 text-left text-slate-700 dark:text-slate-300">Model</th>
                    <th class="px-4 py-2 text-left text-slate-700 dark:text-slate-300">Context</th>
                    <th class="px-4 py-2 text-left text-slate-700 dark:text-slate-300">Speed</th>
                    <th class="px-4 py-2 text-left text-slate-700 dark:text-slate-300">Reasoning</th>
                    <th class="px-4 py-2 text-left text-slate-700 dark:text-slate-300">Tool Use</th>
                </tr>
            </thead>
            <tbody>
                <tr class="border-t border-slate-200 dark:border-slate-700">
                    <td class="px-4 py-2 text-slate-700 dark:text-slate-300"><strong>GPT-4.5</strong></td>
                    <td class="px-4 py-2 text-slate-700 dark:text-slate-300">256K</td>
                    <td class="px-4 py-2 text-slate-700 dark:text-slate-300">Moderate</td>
                    <td class="px-4 py-2 text-slate-700 dark:text-slate-300"><strong>Excellent</strong></td>
                    <td class="px-4 py-2 text-slate-700 dark:text-slate-300">Good</td>
                </tr>
                <tr class="border-t border-slate-200 dark:border-slate-700">
                    <td class="px-4 py-2 text-slate-700 dark:text-slate-300"><strong>GPT-4.1</strong></td>
                    <td class="px-4 py-2 text-slate-700 dark:text-slate-300">1M</td>
                    <td class="px-4 py-2 text-slate-700 dark:text-slate-300">Fast</td>
                    <td class="px-4 py-2 text-slate-700 dark:text-slate-300">Very Good</td>
                    <td class="px-4 py-2 text-slate-700 dark:text-slate-300"><strong>Excellent</strong></td>
                </tr>
                <tr class="border-t border-slate-200 dark:border-slate-700">
                    <td class="px-4 py-2 text-slate-700 dark:text-slate-300"><strong>o3-mini</strong></td>
                    <td class="px-4 py-2 text-slate-700 dark:text-slate-300">200K</td>
                    <td class="px-4 py-2 text-slate-700 dark:text-slate-300"><strong>Very Fast</strong></td>
                    <td class="px-4 py-2 text-slate-700 dark:text-slate-300">Good</td>
                    <td class="px-4 py-2 text-slate-700 dark:text-slate-300">Good</td>
                </tr>
            </tbody>
        </table>
    </div>
    
    <div class="bg-blue-50 dark:bg-blue-950 border-l-4 border-blue-400 dark:border-blue-500 p-4 rounded-r-lg">
        <h4 class="text-lg font-semibold mb-2 text-slate-800 dark:text-slate-200">Choosing the Right GPT Model</h4>
        <p class="text-slate-700 dark:text-slate-300 mb-2">
            The GPT family excels in different scenarios <a href="#source4" class="no-audio text-blue-600 dark:text-blue-400 hover:underline">[4]</a>:
        </p>
        <ul class="list-disc list-inside text-slate-700 dark:text-slate-300 space-y-1">
            <li><strong>GPT-4.5:</strong> When quality and natural interaction are paramount</li>
            <li><strong>GPT-4.1:</strong> For applications requiring massive context and tool integration</li>
            <li><strong>o3-mini:</strong> High-volume processing where speed and cost efficiency matter</li>
        </ul>
    </div>
</div> 